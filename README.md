A full-stack Local LLM Text Generation Service built with FastAPI, gemini-2.0-flash, featuring a Streamlit conversational UI. Deployed as a Docker container on AWS EC2 for scalable and secure API
